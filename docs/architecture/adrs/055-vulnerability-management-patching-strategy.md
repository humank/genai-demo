---
adr_number: 055
title: "Vulnerability Management and Patching Strategy"
date: 2025-10-25
status: "accepted"
supersedes: []
superseded_by: null
related_adrs: [007, 018, 053, 054]
affected_viewpoints: ["deployment", "operational"]
affected_perspectives: ["security", "availability", "evolution"]
---

# ADR-055: Vulnerability Management and Patching Strategy

## Status

**Accepted** - 2025-10-25

## Context

### Problem Statement

The Enterprise E-Commerce Platform requires a comprehensive vulnerability management and patching strategy to:

- Identify security vulnerabilities in code, dependencies, and infrastructure
- Prioritize vulnerabilities based on risk and impact
- Apply security patches in a timely manner
- Minimize system downtime during patching
- Maintain compliance with security standards
- Protect against zero-day exploits

Taiwan's cyber security environment presents additional challenges:

- Frequent targeted attacks exploiting known vulnerabilities
- State-sponsored APT groups actively scanning for vulnerabilities
- Regulatory requirements for timely patching (Taiwan Cyber Security Management Act)
- Need for rapid response to critical vulnerabilities
- Supply chain security concerns

### Business Context

**Business Drivers**:

- Protect platform from security exploits
- Maintain customer trust and platform reputation
- Comply with security regulations and standards
- Minimize business disruption from security incidents
- Enable secure continuous deployment

**Constraints**:

- Must minimize system downtime (< 1 hour per month)
- Cannot disrupt business operations during peak hours
- Must support rollback for failed patches
- Budget: $2,000/month for vulnerability scanning tools

### Technical Context

**Current State**:

- Manual dependency updates
- No automated vulnerability scanning
- Ad-hoc patching process
- No vulnerability prioritization framework
- Limited testing before patching
- No zero-day response plan

**Requirements**:

- Automated vulnerability scanning
- Risk-based prioritization
- Defined patching SLAs
- Automated dependency updates
- Container image scanning
- Zero-day response procedures
- Supply chain security

## Decision Drivers

1. **Security**: Minimize exposure to known vulnerabilities
2. **Speed**: Rapid patching for critical vulnerabilities (< 24 hours)
3. **Reliability**: Minimize failed patches and rollbacks
4. **Compliance**: Meet regulatory patching requirements
5. **Automation**: Automated scanning and patching where possible
6. **Availability**: Minimize system downtime
7. **Cost**: Optimize operational costs
8. **Supply Chain**: Secure software supply chain

## Considered Options

### Option 1: Comprehensive Vulnerability Management (Recommended)

**Description**: Multi-layered vulnerability management with automated scanning, risk-based prioritization, and defined patching SLAs

**Components**:

- **Vulnerability Scanning**: Weekly automated scans (AWS Inspector, Snyk, Trivy)
- **Dependency Management**: Automated dependency updates (Dependabot, Renovate)
- **Container Scanning**: Scan container images before deployment
- **Patching SLAs**: Critical (24h), High (7d), Medium (30d)
- **Testing**: Automated testing before production deployment
- **Zero-Day Response**: Rapid response process for zero-day exploits
- **Supply Chain Security**: SBOM generation and verification

**Pros**:

- ✅ Comprehensive vulnerability coverage
- ✅ Automated scanning and updates
- ✅ Risk-based prioritization
- ✅ Defined SLAs for accountability
- ✅ Supply chain security
- ✅ Compliance-ready
- ✅ Cost-effective ($2,000/month)

**Cons**:

- ⚠️ Implementation complexity
- ⚠️ Potential for breaking changes
- ⚠️ Requires testing infrastructure
- ⚠️ Operational overhead

**Cost**: $2,000/month (Snyk $1,000, AWS Inspector $500, tools $500)

**Risk**: **Low** - Industry best practices

### Option 2: Manual Vulnerability Management

**Description**: Manual vulnerability tracking and patching

**Pros**:

- ✅ Simple to implement
- ✅ Full control over patching
- ✅ Low cost

**Cons**:

- ❌ Slow response to vulnerabilities
- ❌ Human error prone
- ❌ No automated scanning
- ❌ Compliance gaps
- ❌ High operational overhead

**Cost**: $0

**Risk**: **High** - Inadequate for production system

### Option 3: Managed Security Service

**Description**: Outsource vulnerability management to MSSP

**Pros**:

- ✅ Professional expertise
- ✅ 24/7 monitoring
- ✅ Comprehensive coverage

**Cons**:

- ❌ Very high cost ($10,000-20,000/month)
- ❌ Less control over patching
- ❌ Vendor dependency
- ❌ Communication overhead

**Cost**: $15,000/month

**Risk**: **Medium** - Vendor dependency

## Decision Outcome

**Chosen Option**: **Comprehensive Vulnerability Management (Option 1)**

### Rationale

Comprehensive vulnerability management was selected for the following reasons:

1. **Automation**: Automated scanning and updates reduce manual effort
2. **Speed**: Rapid detection and patching of critical vulnerabilities
3. **Risk-Based**: Prioritization based on actual risk and impact
4. **Cost-Effective**: $2,000/month vs $15,000+ for managed service
5. **Compliance**: Meets regulatory patching requirements
6. **Supply Chain**: Protects against supply chain attacks
7. **Scalable**: Handles platform growth automatically

### Vulnerability Scanning

**Scanning Tools**:

**AWS Inspector**: Infrastructure and container scanning

- EC2 instances
- EKS containers
- Lambda functions
- Network reachability
- CVE detection

**Snyk**: Application dependency scanning

- Java dependencies (Maven, Gradle)
- JavaScript dependencies (npm, yarn)
- Python dependencies (pip)
- Container base images
- Infrastructure as Code (CDK)

**Trivy**: Container image scanning

- OS packages
- Application dependencies
- Misconfigurations
- Secrets detection
- License compliance

**Implementation**:

```yaml
# GitHub Actions workflow for vulnerability scanning
name: Vulnerability Scanning

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:

    - cron: '0 2 * * 1'  # Weekly on Monday 2 AM

jobs:
  dependency-scan:
    runs-on: ubuntu-latest
    steps:

      - uses: actions/checkout@v3
      
      - name: Run Snyk to check for vulnerabilities

        uses: snyk/actions/gradle@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
      
      - name: Upload Snyk results to GitHub Security

        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: snyk.sarif
  
  container-scan:
    runs-on: ubuntu-latest
    steps:

      - uses: actions/checkout@v3
      
      - name: Build container image

        run: docker build -t app:${{ github.sha }} .
      
      - name: Run Trivy vulnerability scanner

        uses: aquasecurity/trivy-action@master
        with:
          image-ref: app:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
      
      - name: Upload Trivy results to GitHub Security

        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: trivy-results.sarif
```

### Vulnerability Prioritization

**Risk Scoring Framework**:

**Severity Levels** (CVSS Score):

- **Critical**: CVSS 9.0-10.0
- **High**: CVSS 7.0-8.9
- **Medium**: CVSS 4.0-6.9
- **Low**: CVSS 0.1-3.9

**Exploitability Factors**:

- Public exploit available: +2 priority levels
- Actively exploited in the wild: +3 priority levels
- Network accessible: +1 priority level
- No authentication required: +1 priority level

**Impact Factors**:

- Affects production systems: +2 priority levels
- Affects customer data: +2 priority levels
- Affects payment processing: +3 priority levels
- Affects authentication: +2 priority levels

**Final Priority Calculation**:

```text
Priority = Base Severity + Exploitability + Impact
```

**Priority Levels**:

- **P0 (Critical)**: Score ≥ 9, immediate action required
- **P1 (High)**: Score 7-8, urgent action required
- **P2 (Medium)**: Score 4-6, scheduled action
- **P3 (Low)**: Score < 4, backlog

**Implementation**:

```java
@Service
public class VulnerabilityPrioritizationService {
    
    public Priority calculatePriority(Vulnerability vulnerability) {
        int score = 0;
        
        // Base severity (CVSS score)
        score += vulnerability.getCvssScore();
        
        // Exploitability factors
        if (vulnerability.hasPublicExploit()) {
            score += 2;
        }
        if (vulnerability.isActivelyExploited()) {
            score += 3;
        }
        if (vulnerability.isNetworkAccessible()) {
            score += 1;
        }
        if (!vulnerability.requiresAuthentication()) {
            score += 1;
        }
        
        // Impact factors
        if (vulnerability.affectsProduction()) {
            score += 2;
        }
        if (vulnerability.affectsCustomerData()) {
            score += 2;
        }
        if (vulnerability.affectsPaymentProcessing()) {
            score += 3;
        }
        if (vulnerability.affectsAuthentication()) {
            score += 2;
        }
        
        // Determine priority
        if (score >= 9) {
            return Priority.P0_CRITICAL;
        } else if (score >= 7) {
            return Priority.P1_HIGH;
        } else if (score >= 4) {
            return Priority.P2_MEDIUM;
        } else {
            return Priority.P3_LOW;
        }
    }
}
```

### Patching SLAs

**Service Level Agreements**:

| Priority | Severity | Detection to Patch | Testing | Deployment Window |
|----------|----------|-------------------|---------|-------------------|
| P0 | Critical | 24 hours | Smoke tests only | Immediate (24/7) |
| P1 | High | 7 days | Full test suite | Next maintenance window |
| P2 | Medium | 30 days | Full test suite + UAT | Regular release cycle |
| P3 | Low | 90 days | Full test suite + UAT | Regular release cycle |

**Emergency Patching Process** (P0):

1. **Hour 0-1**: Vulnerability assessment and impact analysis
2. **Hour 1-4**: Patch development and testing
3. **Hour 4-8**: Staging deployment and validation
4. **Hour 8-24**: Production deployment with monitoring

**Standard Patching Process** (P1-P3):

1. **Day 1**: Vulnerability assessment and prioritization
2. **Day 2-3**: Patch development and testing
3. **Day 4-5**: Staging deployment and validation
4. **Day 6-7**: Production deployment (P1) or next release (P2-P3)

**Maintenance Windows**:

- **Primary**: Tuesday 2-4 AM Taiwan time (lowest traffic)
- **Secondary**: Thursday 2-4 AM Taiwan time
- **Emergency**: Any time for P0 critical vulnerabilities

### Automated Dependency Updates

**Dependabot Configuration**:

```yaml
# .github/dependabot.yml
version: 2
updates:
  # Java dependencies

  - package-ecosystem: "gradle"

    directory: "/"
    schedule:
      interval: "weekly"
      day: "monday"
      time: "02:00"
      timezone: "Asia/Taipei"
    open-pull-requests-limit: 10
    reviewers:

      - "security-team"

    labels:

      - "dependencies"
      - "security"

    commit-message:
      prefix: "chore"
      include: "scope"
    # Auto-merge for patch updates
    auto-merge:
      enabled: true
      merge-method: "squash"
      # Only auto-merge patch updates
      update-types:

        - "version-update:semver-patch"
  
  # Docker dependencies

  - package-ecosystem: "docker"

    directory: "/"
    schedule:
      interval: "weekly"
    reviewers:

      - "devops-team"
  
  # GitHub Actions

  - package-ecosystem: "github-actions"

    directory: "/"
    schedule:
      interval: "weekly"
```

**Renovate Configuration** (Alternative):

```json
{
  "extends": ["config:base"],
  "schedule": ["before 3am on Monday"],
  "timezone": "Asia/Taipei",
  "packageRules": [
    {
      "matchUpdateTypes": ["patch"],
      "automerge": true,
      "automergeType": "pr",
      "automergeStrategy": "squash"
    },
    {
      "matchUpdateTypes": ["minor"],
      "automerge": false,
      "reviewers": ["team:developers"]
    },
    {
      "matchUpdateTypes": ["major"],
      "automerge": false,
      "reviewers": ["team:architects", "team:security"]
    },
    {
      "matchPackagePatterns": ["^org.springframework"],
      "groupName": "Spring Framework",
      "reviewers": ["team:backend"]
    }
  ],
  "vulnerabilityAlerts": {
    "enabled": true,
    "labels": ["security", "urgent"],
    "reviewers": ["team:security"]
  }
}
```

### Container Image Scanning

**Scanning Strategy**:

- Scan base images before use
- Scan application images before deployment
- Continuous scanning of deployed images
- Block deployment of images with critical vulnerabilities

**Implementation**:

```yaml
# CDK Pipeline with container scanning
class ContainerScanningStage extends Stage {
  constructor(scope: Construct, id: string, props: StageProps) {
    super(scope, id, props);
    
    // ECR repository with image scanning
    const repository = new ecr.Repository(this, 'AppRepository', {
      imageScanOnPush: true,
      imageTagMutability: ecr.TagMutability.IMMUTABLE,
      lifecycleRules: [
        {
          description: 'Remove untagged images after 7 days',
          maxImageAge: Duration.days(7),
          tagStatus: ecr.TagStatus.UNTAGGED
        }
      ]
    });
    
    // EventBridge rule for scan findings
    const scanRule = new events.Rule(this, 'ScanFindingsRule', {
      eventPattern: {
        source: ['aws.ecr'],
        detailType: ['ECR Image Scan'],
        detail: {
          'scan-status': ['COMPLETE'],
          'finding-severity-counts': {
            'CRITICAL': [{ 'numeric': ['>', 0] }]
          }
        }
      }
    });
    
    // Lambda to block deployment on critical findings
    scanRule.addTarget(new targets.LambdaFunction(blockDeploymentFunction));
  }
}
```

### Zero-Day Response

**Response Process**:

**Phase 1: Detection and Assessment (0-2 hours)**

1. Monitor security advisories (NVD, vendor advisories, Taiwan CERT)
2. Assess impact on our systems
3. Determine exploitability and risk
4. Activate incident response team

**Phase 2: Temporary Mitigation (2-4 hours)**

1. Implement WAF rules to block exploit attempts
2. Network segmentation to limit exposure
3. Increase monitoring and alerting
4. Communicate with stakeholders

**Phase 3: Patch Development (4-12 hours)**

1. Obtain or develop patch
2. Test patch in isolated environment
3. Validate patch effectiveness
4. Prepare rollback plan

**Phase 4: Deployment (12-24 hours)**

1. Deploy to staging environment
2. Validate functionality
3. Deploy to production with monitoring
4. Verify exploit mitigation

**Implementation**:

```java
@Service
public class ZeroDayResponseService {
    
    public void handleZeroDayVulnerability(ZeroDayAlert alert) {
        // Phase 1: Assessment
        VulnerabilityAssessment assessment = assessVulnerability(alert);
        
        if (assessment.isHighRisk()) {
            // Activate incident response team
            incidentResponseService.activateTeam(IncidentType.ZERO_DAY);
            
            // Phase 2: Temporary mitigation
            applyTemporaryMitigation(assessment);
            
            // Phase 3: Patch development
            Patch patch = developOrObtainPatch(assessment);
            
            // Phase 4: Deployment
            deployPatch(patch, assessment);
        }
    }
    
    private void applyTemporaryMitigation(VulnerabilityAssessment assessment) {
        // Implement WAF rules
        if (assessment.isWebExploitable()) {
            wafService.addBlockingRule(assessment.getExploitPattern());
        }
        
        // Network segmentation
        if (assessment.isNetworkExploitable()) {
            networkService.isolateAffectedSystems(assessment.getAffectedSystems());
        }
        
        // Increase monitoring
        monitoringService.increaseAlertSensitivity(assessment.getAffectedComponents());
        
        // Notify stakeholders
        notificationService.sendZeroDayAlert(assessment);
    }
}
```

### Supply Chain Security

**Software Bill of Materials (SBOM)**:

- Generate SBOM for all releases
- Track all dependencies and versions
- Verify dependency integrity
- Monitor for compromised dependencies

**Implementation**:

```bash
# Generate SBOM with CycloneDX
./gradlew cyclonedxBom

# Verify SBOM
cyclonedx-cli validate --input-file build/reports/bom.json

# Upload SBOM to dependency track
curl -X "POST" "https://dependency-track.example.com/api/v1/bom" \
  -H "X-Api-Key: ${API_KEY}" \
  -H "Content-Type: multipart/form-data" \
  -F "project=${PROJECT_UUID}" \
  -F "bom=@build/reports/bom.json"
```

**Dependency Verification**:

```gradle
// build.gradle - Dependency verification
dependencyVerification {
    verify = true
    verifySignatures = true
    verifyMetadata = true
    
    // Trusted keys
    trustedKeys {
        key("org.springframework:spring-core", "B42F6819007F00F88E364FD4036A9C25BF357DD4")
        key("com.fasterxml.jackson.core:jackson-databind", "8A10792983023D5D14C93B488D7F1BEC1E2ECAE7")
    }
}
```

## Impact Analysis

### Stakeholder Impact

| Stakeholder | Impact Level | Description | Mitigation |
|-------------|--------------|-------------|------------|
| Development Team | High | Dependency updates, patch testing | Automated updates, clear process |
| Operations Team | Medium | Patch deployment, monitoring | Automated deployment, runbooks |
| Security Team | Positive | Enhanced vulnerability management | Regular reviews, automated scanning |
| End Users | Low | Brief downtime during patching | Maintenance windows, communication |
| Compliance Team | Positive | Audit trails for patching | Automated reporting |

### Impact Radius

**Selected Impact Radius**: **System**

Affects:

- All application dependencies
- All container images
- All infrastructure components
- Deployment pipelines
- Testing processes

### Risk Assessment

| Risk | Probability | Impact | Mitigation Strategy |
|------|-------------|--------|---------------------|
| Breaking changes from updates | Medium | High | Automated testing, staged rollout |
| Patch deployment failures | Low | High | Rollback procedures, testing |
| False positive vulnerabilities | Medium | Low | Manual review, prioritization |
| Zero-day exploit before patch | Low | Critical | Temporary mitigation, monitoring |
| Supply chain compromise | Low | Critical | SBOM verification, trusted sources |

**Overall Risk Level**: **Low**

## Implementation Plan

### Phase 1: Scanning Infrastructure (Week 1-2)

- [ ] Enable AWS Inspector
- [ ] Set up Snyk for dependency scanning
- [ ] Configure Trivy for container scanning
- [ ] Create vulnerability database
- [ ] Set up GitHub Security integration

### Phase 2: Automated Updates (Week 3-4)

- [ ] Configure Dependabot
- [ ] Set up automated testing pipeline
- [ ] Implement auto-merge for patch updates
- [ ] Create dependency update workflow
- [ ] Test automated update process

### Phase 3: Patching Process (Week 5-6)

- [ ] Define patching SLAs
- [ ] Create patching runbooks
- [ ] Implement vulnerability prioritization
- [ ] Set up maintenance windows
- [ ] Test emergency patching process

### Phase 4: Supply Chain Security (Week 7-8)

- [ ] Implement SBOM generation
- [ ] Set up dependency verification
- [ ] Configure trusted key management
- [ ] Create zero-day response plan
- [ ] Conduct tabletop exercise

### Rollback Strategy

**Trigger Conditions**:

- Patch causes system instability
- Breaking changes in dependencies
- Performance degradation > 10%
- Critical functionality broken

**Rollback Steps**:

1. Revert to previous version
2. Restore from backup if needed
3. Investigate root cause
4. Fix issues
5. Re-deploy with fixes

**Rollback Time**: < 30 minutes

## Monitoring and Success Criteria

### Success Metrics

- ✅ Vulnerability detection time: < 24 hours
- ✅ Critical patch deployment: < 24 hours
- ✅ High patch deployment: < 7 days
- ✅ Patch success rate: > 95%
- ✅ Zero-day response time: < 4 hours
- ✅ Dependency update coverage: 100%
- ✅ Zero unpatched critical vulnerabilities

### Monitoring Plan

**CloudWatch Metrics**:

- `vulnerability.detected` (count by severity)
- `vulnerability.patched` (count by priority)
- `patch.deployment.time` (histogram)
- `patch.deployment.success` (count)
- `dependency.updates` (count)

**Alerts**:

- Critical vulnerability detected
- Patch SLA breach
- Patch deployment failure
- Zero-day vulnerability announced
- Supply chain compromise detected

**Review Schedule**:

- Daily: Review new vulnerabilities
- Weekly: Patch deployment status
- Monthly: Vulnerability trends analysis
- Quarterly: Patching process review

## Consequences

### Positive Consequences

- ✅ **Rapid Patching**: Critical vulnerabilities patched within 24 hours
- ✅ **Automated**: Reduced manual effort with automation
- ✅ **Compliance**: Meets regulatory patching requirements
- ✅ **Supply Chain Security**: Protected against supply chain attacks
- ✅ **Cost-Effective**: $2,000/month for comprehensive coverage
- ✅ **Proactive**: Detect vulnerabilities before exploitation

### Negative Consequences

- ⚠️ **Breaking Changes**: Potential for breaking changes from updates
- ⚠️ **Testing Overhead**: Requires comprehensive testing
- ⚠️ **Operational Overhead**: Monitoring and patch management
- ⚠️ **Downtime**: Brief downtime during patching
- ⚠️ **False Positives**: Some vulnerabilities may not be applicable

### Technical Debt

**Identified Debt**:

1. Manual vulnerability prioritization (acceptable initially)
2. Basic SBOM generation (no verification)
3. No automated rollback for failed patches
4. Limited zero-day simulation testing

**Debt Repayment Plan**:

- **Q2 2026**: Implement ML-powered vulnerability prioritization
- **Q3 2026**: Automate rollback for failed patches
- **Q4 2026**: Implement comprehensive SBOM verification
- **2027**: Regular zero-day response drills

## Related Decisions

- [ADR-007: Use AWS CDK for Infrastructure](007-use-aws-cdk-for-infrastructure.md) - Infrastructure patching
- [ADR-018: Container Orchestration with AWS EKS](018-container-orchestration-eks.md) - Container patching
- [ADR-053: Security Monitoring and Incident Response](053-security-monitoring-incident-response.md) - Security monitoring integration
- [ADR-054: Data Loss Prevention (DLP) Strategy](054-data-loss-prevention-strategy.md) - Data protection

## Notes

### Vulnerability Scanning Schedule

- **Weekly**: Full system scan (Monday 2 AM)
- **Daily**: Dependency check for new vulnerabilities
- **Continuous**: Container image scanning on push
- **On-Demand**: Manual scan before major releases

### Patching Best Practices

1. **Test First**: Always test patches in staging before production
2. **Backup**: Create backup before applying patches
3. **Monitor**: Closely monitor system after patching
4. **Communicate**: Notify stakeholders of maintenance windows
5. **Document**: Document all patches applied

### Emergency Contact List

- **Security Team Lead**: <security-lead@example.com>
- **DevOps On-Call**: <devops-oncall@example.com>
- **PagerDuty**: <https://example.pagerduty.com>
- **Taiwan CERT**: <cert@twcert.org.tw>

---

**Document Status**: ✅ Accepted  
**Last Reviewed**: 2025-10-25  
**Next Review**: 2026-01-25 (Quarterly)
