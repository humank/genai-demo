# Staging 環境測試策略\n\n## 📋 **概覽**\n\n本機開發環境 (Local Profile) 完全使用記憶體實現來模擬所有外部依賴，包括分散式鎖、快取等。\n所有涉及真實外部服務（Redis、ElastiCache、MSK 等）的測試都必須在 Staging 環境中進行。\n\n**核心原則**:\n- 🏠 **Local/Test**: 100% 記憶體模擬，零外部依賴\n- 🎭 **Staging**: 真實 AWS 服務整合測試\n- 🚀 **Production**: 經過 Staging 驗證的配置\n\n## 🎯 **測試分層策略**\n\n### **本機測試 (Local/Test Profile)**\n```\n契約測試 → DistributedLockManagerContractTest\n記憶體實現測試 → InMemoryDistributedLockManagerTest\n單元測試 → 業務邏輯測試\n整合測試 → 記憶體實現 + H2\nCucumber 測試 → 記憶體實現 + H2\n```\n\n**特點**:\n- ✅ 零外部依賴\n- ✅ 快速執行 (< 2 分鐘)\n- ✅ 100% 可重現\n- ✅ 契約驗證完整\n\n### **Staging 環境測試**\n```\nRedis 整合測試 → 真實 ElastiCache\n資料庫整合測試 → 真實 RDS\nKafka 整合測試 → 真實 MSK\n端到端測試 → 完整 AWS 服務鏈\n效能測試 → 真實網路延遲\n故障轉移測試 → 真實高可用性\n```\n\n**特點**:\n- 🔗 真實 AWS 服務\n- 📊 真實效能數據\n- 🔄 故障轉移驗證\n- 💰 產生 AWS 費用\n\n## 🏗️ **Staging 環境測試實施**\n\n### **1. Redis/ElastiCache 整合測試**\n\n**測試目標**: 驗證 Redis 分散式鎖在真實環境中的行為\n\n**測試腳本範例**:\n```bash\n#!/bin/bash\n# staging-redis-tests.sh\n\necho \"🔧 Setting up Staging Redis Tests...\"\n\n# 設定環境變數\nexport SPRING_PROFILES_ACTIVE=staging\nexport REDIS_MODE=CLUSTER\nexport REDIS_CLUSTER_NODES=${STAGING_REDIS_CLUSTER_NODES}\nexport REDIS_PASSWORD=${STAGING_REDIS_PASSWORD}\n\necho \"📋 Running Redis Integration Tests...\"\n\n# 基本連線測試\necho \"Testing Redis connectivity...\"\ncurl -f http://staging-app/actuator/health/redis || exit 1\n\n# 分散式鎖測試\necho \"Testing distributed locks...\"\n# 使用 REST API 或 CLI 工具測試鎖操作\n\n# 並發測試\necho \"Testing concurrent lock operations...\"\n# 啟動多個並發請求測試鎖競爭\n\n# 故障轉移測試\necho \"Testing Redis failover...\"\n# 模擬節點故障，測試自動故障轉移\n\necho \"✅ Redis Integration Tests Completed\"\n```\n\n**測試內容**:\n- Redis 連線和認證\n- 分散式鎖的獲取和釋放\n- 鎖過期和自動清理\n- 連線池管理\n- 故障轉移和恢復\n- 效能基準測試\n\n### **2. 資料庫整合測試**\n\n**測試腳本範例**:\n```bash\n#!/bin/bash\n# staging-database-tests.sh\n\necho \"🔧 Setting up Staging Database Tests...\"\n\n# 設定環境變數\nexport SPRING_PROFILES_ACTIVE=staging\nexport DB_HOST=${STAGING_DB_HOST}\nexport DB_USERNAME=${STAGING_DB_USERNAME}\nexport DB_PASSWORD=${STAGING_DB_PASSWORD}\n\necho \"📋 Running Database Integration Tests...\"\n\n# 連線測試\necho \"Testing database connectivity...\"\npsql -h $DB_HOST -U $DB_USERNAME -d genai_demo -c \"SELECT 1;\" || exit 1\n\n# Flyway Migration 測試\necho \"Testing Flyway migrations...\"\n# 執行應用程式，驗證 Migration 成功\n\n# 效能測試\necho \"Testing database performance...\"\n# 執行效能測試查詢\n\n# 交易測試\necho \"Testing transaction management...\"\n# 測試交易隔離和回滾\n\necho \"✅ Database Integration Tests Completed\"\n```\n\n### **3. MSK Kafka 整合測試**\n\n**測試腳本範例**:\n```bash\n#!/bin/bash\n# staging-kafka-tests.sh\n\necho \"🔧 Setting up Staging Kafka Tests...\"\n\n# 設定環境變數\nexport SPRING_PROFILES_ACTIVE=staging\nexport KAFKA_BOOTSTRAP_SERVERS=${STAGING_KAFKA_BOOTSTRAP_SERVERS}\n\necho \"📋 Running Kafka Integration Tests...\"\n\n# 連線測試\necho \"Testing Kafka connectivity...\"\nkafka-topics --bootstrap-server $KAFKA_BOOTSTRAP_SERVERS --list || exit 1\n\n# 事件發布測試\necho \"Testing event publishing...\"\n# 發布測試事件\n\n# 事件消費測試\necho \"Testing event consumption...\"\n# 驗證事件被正確消費\n\n# 故障恢復測試\necho \"Testing Kafka resilience...\"\n# 測試網路中斷後的恢復\n\necho \"✅ Kafka Integration Tests Completed\"\n```\n\n### **4. 端到端測試**\n\n**測試腳本範例**:\n```bash\n#!/bin/bash\n# staging-e2e-tests.sh\n\necho \"🔧 Setting up Staging E2E Tests...\"\n\n# 設定完整的 Staging 環境\nexport SPRING_PROFILES_ACTIVE=staging\n# ... 所有環境變數\n\necho \"📋 Running End-to-End Tests...\"\n\n# 完整業務流程測試\necho \"Testing complete customer journey...\"\n# 1. 建立客戶\n# 2. 建立訂單\n# 3. 處理付款\n# 4. 更新庫存\n# 5. 發送通知\n\n# 跨服務資料一致性測試\necho \"Testing cross-service data consistency...\"\n# 驗證事件驅動的資料一致性\n\n# 效能和延遲測試\necho \"Testing performance under load...\"\n# 執行負載測試\n\necho \"✅ End-to-End Tests Completed\"\n```\n\n## 🚀 **CI/CD 整合**\n\n### **GitHub Actions 工作流程**\n\n```yaml\n# .github/workflows/staging-integration-tests.yml\nname: Staging Integration Tests\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n  schedule:\n    - cron: '0 2 * * *'  # 每日凌晨 2 點執行\n  workflow_dispatch:  # 手動觸發\n\njobs:\n  staging-tests:\n    runs-on: ubuntu-latest\n    if: |\n      github.event_name == 'schedule' || \n      github.event_name == 'workflow_dispatch' ||\n      contains(github.event.head_commit.message, '[staging-test]')\n    \n    steps:\n    - uses: actions/checkout@v4\n    \n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v4\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: ap-northeast-1\n    \n    - name: Run Redis Integration Tests\n      env:\n        STAGING_REDIS_CLUSTER_NODES: ${{ secrets.STAGING_REDIS_CLUSTER_NODES }}\n        STAGING_REDIS_PASSWORD: ${{ secrets.STAGING_REDIS_PASSWORD }}\n      run: |\n        chmod +x scripts/staging-redis-tests.sh\n        ./scripts/staging-redis-tests.sh\n    \n    - name: Run Database Integration Tests\n      env:\n        STAGING_DB_HOST: ${{ secrets.STAGING_DB_HOST }}\n        STAGING_DB_USERNAME: ${{ secrets.STAGING_DB_USERNAME }}\n        STAGING_DB_PASSWORD: ${{ secrets.STAGING_DB_PASSWORD }}\n      run: |\n        chmod +x scripts/staging-database-tests.sh\n        ./scripts/staging-database-tests.sh\n    \n    - name: Run Kafka Integration Tests\n      env:\n        STAGING_KAFKA_BOOTSTRAP_SERVERS: ${{ secrets.STAGING_KAFKA_BOOTSTRAP_SERVERS }}\n      run: |\n        chmod +x scripts/staging-kafka-tests.sh\n        ./scripts/staging-kafka-tests.sh\n    \n    - name: Run End-to-End Tests\n      env:\n        STAGING_APP_URL: ${{ secrets.STAGING_APP_URL }}\n      run: |\n        chmod +x scripts/staging-e2e-tests.sh\n        ./scripts/staging-e2e-tests.sh\n    \n    - name: Upload Test Reports\n      uses: actions/upload-artifact@v4\n      if: always()\n      with:\n        name: staging-test-reports\n        path: |\n          test-reports/\n          logs/\n    \n    - name: Notify on Failure\n      if: failure()\n      uses: 8398a7/action-slack@v3\n      with:\n        status: failure\n        text: 'Staging integration tests failed! Please check the logs.'\n      env:\n        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n```\n\n## 📊 **測試監控和報告**\n\n### **測試結果儀表板**\n\n使用 CloudWatch 或 Grafana 建立測試結果儀表板：\n\n- **測試執行狀態**: 成功/失敗趨勢\n- **測試執行時間**: 各類測試的執行時間\n- **服務健康狀態**: Redis、RDS、MSK 的健康狀態\n- **錯誤率分析**: 錯誤類型和頻率分析\n- **效能指標**: 響應時間、吞吐量趨勢\n\n### **告警配置**\n\n```yaml\n# CloudWatch Alarms for Staging Tests\nStagingTestFailureAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    AlarmName: StagingTestFailure\n    AlarmDescription: Staging integration tests are failing\n    MetricName: TestFailureRate\n    Namespace: GenAIDemo/StagingTests\n    Statistic: Average\n    Period: 300\n    EvaluationPeriods: 1\n    Threshold: 0.1  # 10% 失敗率\n    ComparisonOperator: GreaterThanThreshold\n    AlarmActions:\n      - !Ref SNSTopicArn\n```\n\n## 🔧 **故障排除指南**\n\n### **常見問題和解決方案**\n\n#### **1. Redis 連線失敗**\n```bash\n# 檢查 ElastiCache 端點\naws elasticache describe-cache-clusters --show-cache-node-info\n\n# 檢查安全群組設定\naws ec2 describe-security-groups --group-ids sg-xxx\n\n# 測試網路連線\ntelnet redis-cluster-endpoint 6379\n```\n\n#### **2. 資料庫連線超時**\n```bash\n# 檢查 RDS 實例狀態\naws rds describe-db-instances --db-instance-identifier staging-db\n\n# 檢查網路連線\ntelnet staging-db-endpoint 5432\n\n# 檢查連線池配置\necho \"SELECT * FROM pg_stat_activity;\" | psql -h $DB_HOST -U $DB_USERNAME -d genai_demo\n```\n\n#### **3. Kafka 連線問題**\n```bash\n# 檢查 MSK 叢集狀態\naws kafka describe-cluster --cluster-arn arn:aws:kafka:...\n\n# 檢查 IAM 權限\naws sts get-caller-identity\n\n# 測試 Kafka 連線\nkafka-console-producer --bootstrap-server $KAFKA_BOOTSTRAP_SERVERS --topic test-topic\n```\n\n### **除錯工具和技巧**\n\n```bash\n# 啟用詳細日誌\nexport LOGGING_LEVEL_SOLID_HUMANK_GENAIDEMO=DEBUG\nexport LOGGING_LEVEL_ORG_SPRINGFRAMEWORK=INFO\n\n# 檢查應用程式健康狀態\ncurl -s http://staging-app/actuator/health | jq .\n\n# 檢查指標\ncurl -s http://staging-app/actuator/metrics | jq .\n\n# 檢查環境變數\ncurl -s http://staging-app/actuator/env | jq .\n```\n\n## 📋 **最佳實踐**\n\n### **✅ 建議做法**\n\n1. **測試隔離**: 每個測試使用獨立的資源 (不同的 key prefix、topic 等)\n2. **資源清理**: 測試後自動清理建立的資源\n3. **重試機制**: 對網路相關的測試實施適當的重試\n4. **超時設定**: 設定合理的超時時間避免測試掛起\n5. **監控整合**: 將測試結果整合到監控系統\n6. **成本控制**: 合理安排測試執行時間，控制 AWS 費用\n7. **資料安全**: 不要在測試中使用真實的敏感資料\n\n### **🚨 注意事項**\n\n1. **環境穩定**: 確保 Staging 環境的穩定性\n2. **版本一致**: 確保測試的程式碼版本與部署版本一致\n3. **資源限制**: 注意 AWS 服務的配額和限制\n4. **網路安全**: 確保測試環境的網路安全配置\n5. **資料隱私**: 遵循資料保護法規\n\n## 🔗 **相關資源**\n\n- Profile 管理策略\n- [分散式鎖契約測試](../../app/src/test/java/solid/humank/genaidemo/infrastructure/common/lock/DistributedLockManagerContractTest.java)\n- 記憶體鎖實現測試\n- [部署視點](../viewpoints/deployment/README.md)\n- [運營視點](../viewpoints/operational/README.md)\n\n---\n\n**最後更新**: 2025年9月24日 上午9:45 (台北時間)  \n**維護者**: Development Team  \n**版本**: 2.0.0  \n**狀態**: Active - 純記憶體模擬策略\n"
